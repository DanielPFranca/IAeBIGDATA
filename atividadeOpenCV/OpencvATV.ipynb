{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codigo open cv\n",
    "import cv2\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\dsadm\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (4.8.1.78)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\dsadm\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from opencv-python) (1.24.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\dsadm\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\dsadm\\Desktop\\daniel\\atividadeOpenCV\\OpencvATV.ipynb Cell 3\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dsadm/Desktop/daniel/atividadeOpenCV/OpencvATV.ipynb#W2sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m face_cascade \u001b[39m=\u001b[39m load_face_detection_model()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dsadm/Desktop/daniel/atividadeOpenCV/OpencvATV.ipynb#W2sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39m# Realizar a detecção de rostos na imagem\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/dsadm/Desktop/daniel/atividadeOpenCV/OpencvATV.ipynb#W2sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m detect_faces(image_path, face_cascade)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dsadm/Desktop/daniel/atividadeOpenCV/OpencvATV.ipynb#W2sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39m# Realizar a análise de expressões faciais (opcional)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dsadm/Desktop/daniel/atividadeOpenCV/OpencvATV.ipynb#W2sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m analyze_facial_expression(image_path)\n",
      "\u001b[1;32mc:\\Users\\dsadm\\Desktop\\daniel\\atividadeOpenCV\\OpencvATV.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dsadm/Desktop/daniel/atividadeOpenCV/OpencvATV.ipynb#W2sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# Exibir a imagem com os rostos detectados\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dsadm/Desktop/daniel/atividadeOpenCV/OpencvATV.ipynb#W2sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m cv2\u001b[39m.\u001b[39mimshow(\u001b[39m'\u001b[39m\u001b[39mDetecção de Rostos\u001b[39m\u001b[39m'\u001b[39m, image)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/dsadm/Desktop/daniel/atividadeOpenCV/OpencvATV.ipynb#W2sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m cv2\u001b[39m.\u001b[39;49mwaitKey(\u001b[39m0\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dsadm/Desktop/daniel/atividadeOpenCV/OpencvATV.ipynb#W2sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m cv2\u001b[39m.\u001b[39mdestroyAllWindows()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Função para carregar o modelo de detecção facial do OpenCV\n",
    "def load_face_detection_model():\n",
    "    return cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Função para realizar a detecção de rostos em uma imagem\n",
    "def detect_faces(image_path, face_cascade):\n",
    "    image = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detectar rostos na imagem\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    # Desenhar retângulos ao redor dos rostos detectados\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(image, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "    # Exibir a imagem com os rostos detectados\n",
    "    cv2.imshow('Detecção de Rostos', image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Função para realizar a análise de expressões faciais usando um modelo PyTorch (opcional)\n",
    "def analyze_facial_expression(image_path):\n",
    "    # Carregar o modelo pré-treinado para análise de expressões faciais (exemplo: ResNet-18)\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    model.eval()\n",
    "\n",
    "    # Transformações para pré-processar a imagem\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # Carregar e pré-processar a imagem\n",
    "    image = Image.open(image_path)\n",
    "    input_tensor = transform(image)\n",
    "    input_batch = input_tensor.unsqueeze(0)\n",
    "\n",
    "    # Realizar a inferência\n",
    "    with torch.no_grad():\n",
    "        output = model(input_batch)\n",
    "\n",
    "    # Converter as probabilidades em uma expressão facial\n",
    "    _, predicted_idx = torch.max(output, 1)\n",
    "    expression_labels = ['Feliz', 'Triste', 'Surpreso', 'Bravo', 'Neutro']\n",
    "    predicted_expression = expression_labels[predicted_idx]\n",
    "\n",
    "    print(f'Expressão Facial Predita: {predicted_expression}')\n",
    "\n",
    "# Caminho para a imagem que será analisada\n",
    "image_path = 'imagem.jpg'\n",
    "\n",
    "# Carregar o modelo de detecção facial\n",
    "face_cascade = load_face_detection_model()\n",
    "\n",
    "# Realizar a detecção de rostos na imagem\n",
    "detect_faces(image_path, face_cascade)\n",
    "\n",
    "# Realizar a análise de expressões faciais (opcional)\n",
    "analyze_facial_expression(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
